{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d000ee7e-88cb-4217-8538-57823e82d01b",
   "metadata": {},
   "source": [
    "# Workshop 001: Proceso ETL de Datos de Candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd722f-f151-489d-aa31-84d0a1875e84",
   "metadata": {},
   "source": [
    "Universidad Autónoma de Occidente\n",
    "\n",
    "Maestría en Inteligencia Artificial y Ciencia de Datos\n",
    "\n",
    "Procesamiento y Extracción de Información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec11742-af87-42ae-ab90-a2f63e34790c",
   "metadata": {},
   "source": [
    "**Estudiante:** Juan Diego Díaz Guzmán\n",
    "\n",
    "**Código de Estudiante:** 22500222\n",
    "\n",
    "**Profesor:** Javier Alejandro Vergara\n",
    "\n",
    "**Fecha:** 20/02/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578fd63-4f09-43f7-9a57-8ef21bf8efae",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Este nootebook implementa un proceso ETL, para analizar los candidatos de proceso de selección. El proyecto incluye las siguientes etapas:\n",
    "\n",
    "1. **Extracción**: Lectura de datos desde un archivo CSV que contiene información de 50,000 candidatos.\n",
    "2. **Transformación**: Procesamiento y limpieza de datos, incluyendo:\n",
    "   - Normalización de campos\n",
    "   - Cálculo de métricas de contratación\n",
    "   - Categorización de candidatos\n",
    "3. **Carga**: Almacenamiento de datos en una base de datos PostgreSQL para su posterior análisis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218a13e-ba64-43aa-b483-39a424475e95",
   "metadata": {},
   "source": [
    "# Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d180ccf-73a9-45f1-b686-6df68226bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Configuración de visualización de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "print(\"Librerías importadas exitosamente!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b778205-426d-4014-8210-906d0275dcd6",
   "metadata": {},
   "source": [
    "# Lectura y Exploración del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bdedc71-a4b8-4837-9a99-3390ae9771b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2091992626.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(df.head())a\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ruta del archivo CSV\n",
    "    csv_path = '../data/candidates.csv'\n",
    "    \n",
    "    print(f\"Leyendo archivo: {csv_path}\")\n",
    "    \n",
    "    # Lectura del CSV\n",
    "    df = pd.read_csv(csv_path, \n",
    "                     delimiter=';',\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "    print(\"\\nArchivo leído exitosamente!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al leer el archivo: {e}\")\n",
    "    \n",
    "#Exploración inicial de datos\n",
    "if 'df' in locals():\n",
    "    print(\"\\nDimensiones del DataFrame:\")\n",
    "    print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nColumnas del DataFrame:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(\"\\nPrimeras 5 filas:\")\n",
    "    print(df.head())a\n",
    "    \n",
    "    print(\"\\nInformación del DataFrame:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nEstadísticas descriptivas:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nValores nulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "#Validación básica de datos\n",
    "def validate_data(df):\n",
    "    \"\"\"\n",
    "    Realiza validaciones básicas en los datos.\n",
    "    \"\"\"\n",
    "    validations = {\n",
    "        \"Registros totales\": len(df),\n",
    "        \"Columnas esperadas presentes\": all(col in df.columns for col in [\n",
    "            'First Name', 'Last Name', 'Email', 'Application Date', 'Country',\n",
    "            'YOE', 'Seniority', 'Technology', 'Code Challenge Score', 'Technical Interview Score'\n",
    "        ]),\n",
    "        \"Emails únicos\": df['Email'].nunique(),\n",
    "        \"Rango de scores válido\": (\n",
    "            (df['Code Challenge Score'].between(0, 10)) & \n",
    "            (df['Technical Interview Score'].between(0, 10))\n",
    "        ).all()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nResultados de la validación:\")\n",
    "    for check, result in validations.items():\n",
    "        print(f\"{check}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c703f-c6d5-4d2f-aa62-c70e48362947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
