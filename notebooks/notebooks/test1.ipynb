{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d000ee7e-88cb-4217-8538-57823e82d01b",
   "metadata": {},
   "source": [
    "# Workshop 001: Proceso ETL de Datos de Candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd722f-f151-489d-aa31-84d0a1875e84",
   "metadata": {},
   "source": [
    "Universidad Autónoma de Occidente\n",
    "\n",
    "Maestría en Inteligencia Artificial y Ciencia de Datos\n",
    "\n",
    "Procesamiento y Extracción de Información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec11742-af87-42ae-ab90-a2f63e34790c",
   "metadata": {},
   "source": [
    "**Estudiante:** Juan Diego Díaz Guzmán\n",
    "\n",
    "**Código de Estudiante:** 22500222\n",
    "\n",
    "**Profesor:** Javier Alejandro Vergara\n",
    "\n",
    "**Fecha:** 20/02/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578fd63-4f09-43f7-9a57-8ef21bf8efae",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Este nootebook implementa un proceso ETL, para analizar los candidatos de proceso de selección. El proyecto incluye las siguientes etapas:\n",
    "\n",
    "1. **Extracción**: Lectura de datos desde un archivo CSV que contiene información de 50,000 candidatos.\n",
    "2. **Transformación**: Procesamiento y limpieza de datos, incluyendo:\n",
    "   - Normalización de campos\n",
    "   - Cálculo de métricas de contratación\n",
    "   - Categorización de candidatos\n",
    "3. **Carga**: Almacenamiento de datos en una base de datos PostgreSQL para su posterior análisis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218a13e-ba64-43aa-b483-39a424475e95",
   "metadata": {},
   "source": [
    "# Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d180ccf-73a9-45f1-b686-6df68226bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Configuración de visualización de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "print(\"Librerías importadas exitosamente!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b778205-426d-4014-8210-906d0275dcd6",
   "metadata": {},
   "source": [
    "# Lectura y Exploración del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdedc71-a4b8-4837-9a99-3390ae9771b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo archivo: ../data/candidates.csv\n",
      "\n",
      "Archivo leído exitosamente!\n",
      "\n",
      "Dimensiones del DataFrame:\n",
      "Filas: 50000, Columnas: 10\n",
      "\n",
      "Columnas del DataFrame:\n",
      "['First Name', 'Last Name', 'Email', 'Application Date', 'Country', 'YOE', 'Seniority', 'Technology', 'Code Challenge Score', 'Technical Interview Score']\n",
      "\n",
      "Primeras 5 filas:\n",
      "   First Name   Last Name                      Email Application Date  \\\n",
      "0  Bernadette   Langworth        leonard91@yahoo.com       2021-02-26   \n",
      "1      Camryn    Reynolds        zelda56@hotmail.com       2021-09-09   \n",
      "2       Larue      Spinka   okey_schultz41@gmail.com       2020-04-14   \n",
      "3        Arch      Spinka     elvera_kulas@yahoo.com       2020-10-01   \n",
      "4       Larue  Altenwerth  minnie.gislason@gmail.com       2020-05-20   \n",
      "\n",
      "   Country  YOE  Seniority                         Technology  \\\n",
      "0   Norway    2     Intern                      Data Engineer   \n",
      "1   Panama   10     Intern                      Data Engineer   \n",
      "2  Belarus    4  Mid-Level                     Client Success   \n",
      "3  Eritrea   25    Trainee                          QA Manual   \n",
      "4  Myanmar   13  Mid-Level  Social Media Community Management   \n",
      "\n",
      "   Code Challenge Score  Technical Interview Score  \n",
      "0                     3                          3  \n",
      "1                     2                         10  \n",
      "2                    10                          9  \n",
      "3                     7                          1  \n",
      "4                     9                          7  \n",
      "\n",
      "Información del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   First Name                 50000 non-null  object\n",
      " 1   Last Name                  50000 non-null  object\n",
      " 2   Email                      50000 non-null  object\n",
      " 3   Application Date           50000 non-null  object\n",
      " 4   Country                    50000 non-null  object\n",
      " 5   YOE                        50000 non-null  int64 \n",
      " 6   Seniority                  50000 non-null  object\n",
      " 7   Technology                 50000 non-null  object\n",
      " 8   Code Challenge Score       50000 non-null  int64 \n",
      " 9   Technical Interview Score  50000 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "                YOE  Code Challenge Score  Technical Interview Score\n",
      "count  50000.000000          50000.000000               50000.000000\n",
      "mean      15.286980              4.996400                   5.003880\n",
      "std        8.830652              3.166896                   3.165082\n",
      "min        0.000000              0.000000                   0.000000\n",
      "25%        8.000000              2.000000                   2.000000\n",
      "50%       15.000000              5.000000                   5.000000\n",
      "75%       23.000000              8.000000                   8.000000\n",
      "max       30.000000             10.000000                  10.000000\n",
      "\n",
      "Valores nulos por columna:\n",
      "First Name                   0\n",
      "Last Name                    0\n",
      "Email                        0\n",
      "Application Date             0\n",
      "Country                      0\n",
      "YOE                          0\n",
      "Seniority                    0\n",
      "Technology                   0\n",
      "Code Challenge Score         0\n",
      "Technical Interview Score    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ruta del archivo CSV\n",
    "    csv_path = '../data/candidates.csv'\n",
    "    \n",
    "    print(f\"Leyendo archivo: {csv_path}\")\n",
    "    \n",
    "    # Lectura del CSV\n",
    "    df = pd.read_csv(csv_path, \n",
    "                     delimiter=';',\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "    print(\"\\nArchivo leído exitosamente!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al leer el archivo: {e}\")\n",
    "    \n",
    "#Exploración inicial de datos\n",
    "if 'df' in locals():\n",
    "    print(\"\\nDimensiones del DataFrame:\")\n",
    "    print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nColumnas del DataFrame:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(\"\\nPrimeras 5 filas:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nInformación del DataFrame:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nEstadísticas descriptivas:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nValores nulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "#Validación básica de datos\n",
    "def validate_data(df):\n",
    "    \"\"\"\n",
    "    Realiza validaciones básicas en los datos.\n",
    "    \"\"\"\n",
    "    validations = {\n",
    "        \"Registros totales\": len(df),\n",
    "        \"Columnas esperadas presentes\": all(col in df.columns for col in [\n",
    "            'First Name', 'Last Name', 'Email', 'Application Date', 'Country',\n",
    "            'YOE', 'Seniority', 'Technology', 'Code Challenge Score', 'Technical Interview Score'\n",
    "        ]),\n",
    "        \"Emails únicos\": df['Email'].nunique(),\n",
    "        \"Rango de scores válido\": (\n",
    "            (df['Code Challenge Score'].between(0, 10)) & \n",
    "            (df['Technical Interview Score'].between(0, 10))\n",
    "        ).all()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nResultados de la validación:\")\n",
    "    for check, result in validations.items():\n",
    "        print(f\"{check}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407983d-dc37-49b2-9043-c5e0cd8f5dff",
   "metadata": {},
   "source": [
    "# Funciones de Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff33e5b-1ca0-4c40-af3e-ba3526ed71b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión a la base de datos establecida exitosamente!\n"
     ]
    }
   ],
   "source": [
    "def load_config(file_path=\"config.yaml\"):\n",
    "    \"\"\"\n",
    "    Carga la configuración desde el archivo YAML.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Ruta al archivo de configuración\n",
    "        \n",
    "    Returns:\n",
    "        dict: Configuración cargada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return yaml.safe_load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar la configuración: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"\n",
    "    Crea una conexión a la base de datos PostgreSQL.\n",
    "    \n",
    "    Returns:\n",
    "        connection: Objeto de conexión a PostgreSQL\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "    if not config:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Obtener configuración de la base de datos\n",
    "        db_config = config[\"database\"]\n",
    "        \n",
    "        # Crear conexión\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=db_config[\"name\"],\n",
    "            user=db_config[\"user\"],\n",
    "            password=db_config[\"password\"],\n",
    "            host=db_config[\"host\"],\n",
    "            port=db_config[\"port\"]\n",
    "        )\n",
    "        \n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error al conectar a la base de datos: {e}\")\n",
    "        return None\n",
    "\n",
    "# Probar la conexión\n",
    "try:\n",
    "    conn = get_db_connection()\n",
    "    if conn:\n",
    "        print(\"Conexión a la base de datos establecida exitosamente!\")\n",
    "        conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8aaa40-a087-4855-ba82-e7748b2d8a72",
   "metadata": {},
   "source": [
    "**Creación de Estructura en Base de Datos**\n",
    "\n",
    "En esta sección crearemos la tabla en PostgreSQL para almacenar los datos de los candidatos. \n",
    "La tabla contendrá los siguientes campos:\n",
    "- First Name\n",
    "- Last Name\n",
    "- Email\n",
    "- Application Date\n",
    "- Country\n",
    "- YOE (Years of Experience)\n",
    "- Seniority\n",
    "- Technology\n",
    "- Code Challenge Score\n",
    "- Technical Interview Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88db91-0ffc-434b-959a-c9c17a64f63b",
   "metadata": {},
   "source": [
    "**Creación de la Tabla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f20fbb-0498-46fb-a5fc-e60b9a408237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'candidates' creada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "def create_candidates_table():\n",
    "    \"\"\"\n",
    "    Crea la tabla candidates en la base de datos.\n",
    "    \"\"\"\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS candidates (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        first_name VARCHAR(100),\n",
    "        last_name VARCHAR(100),\n",
    "        email VARCHAR(150),\n",
    "        application_date DATE,\n",
    "        country VARCHAR(100),\n",
    "        years_of_experience INTEGER,\n",
    "        seniority VARCHAR(50),\n",
    "        technology VARCHAR(100),\n",
    "        code_challenge_score DECIMAL(4,2),\n",
    "        technical_interview_score DECIMAL(4,2),\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # Obtener conexión\n",
    "        conn = get_db_connection()\n",
    "        conn.autocommit = True\n",
    "        \n",
    "        # Crear cursor y ejecutar query\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(create_table_query)\n",
    "            print(\"Tabla 'candidates' creada exitosamente!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear la tabla: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Crear la tabla\n",
    "create_candidates_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f92102-4e62-4e2c-bb97-8e7f928f1f02",
   "metadata": {},
   "source": [
    "**Carga de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30decd80-de87-4881-ad3b-e4dc347bfa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertados registros 0 a 1000\n",
      "Insertados registros 1000 a 2000\n",
      "Insertados registros 2000 a 3000\n",
      "Insertados registros 3000 a 4000\n",
      "Insertados registros 4000 a 5000\n",
      "Insertados registros 5000 a 6000\n",
      "Insertados registros 6000 a 7000\n",
      "Insertados registros 7000 a 8000\n",
      "Insertados registros 8000 a 9000\n",
      "Insertados registros 9000 a 10000\n",
      "Insertados registros 10000 a 11000\n",
      "Insertados registros 11000 a 12000\n",
      "Insertados registros 12000 a 13000\n",
      "Insertados registros 13000 a 14000\n",
      "Insertados registros 14000 a 15000\n",
      "Insertados registros 15000 a 16000\n",
      "Insertados registros 16000 a 17000\n",
      "Insertados registros 17000 a 18000\n",
      "Insertados registros 18000 a 19000\n",
      "Insertados registros 19000 a 20000\n",
      "Insertados registros 20000 a 21000\n",
      "Insertados registros 21000 a 22000\n",
      "Insertados registros 22000 a 23000\n",
      "Insertados registros 23000 a 24000\n",
      "Insertados registros 24000 a 25000\n",
      "Insertados registros 25000 a 26000\n",
      "Insertados registros 26000 a 27000\n",
      "Insertados registros 27000 a 28000\n",
      "Insertados registros 28000 a 29000\n",
      "Insertados registros 29000 a 30000\n",
      "Insertados registros 30000 a 31000\n",
      "Insertados registros 31000 a 32000\n",
      "Insertados registros 32000 a 33000\n",
      "Insertados registros 33000 a 34000\n",
      "Insertados registros 34000 a 35000\n",
      "Insertados registros 35000 a 36000\n",
      "Insertados registros 36000 a 37000\n",
      "Insertados registros 37000 a 38000\n",
      "Insertados registros 38000 a 39000\n",
      "Insertados registros 39000 a 40000\n",
      "Insertados registros 40000 a 41000\n",
      "Insertados registros 41000 a 42000\n",
      "Insertados registros 42000 a 43000\n",
      "Insertados registros 43000 a 44000\n",
      "Insertados registros 44000 a 45000\n",
      "Insertados registros 45000 a 46000\n",
      "Insertados registros 46000 a 47000\n",
      "Insertados registros 47000 a 48000\n",
      "Insertados registros 48000 a 49000\n",
      "Insertados registros 49000 a 50000\n",
      "¡Todos los datos han sido insertados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "def insert_candidates_data(df, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Inserta los datos en la tabla candidates en lotes.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame con los datos a insertar\n",
    "        batch_size (int): Tamaño del lote para inserción\n",
    "    \"\"\"\n",
    "    # Query de inserción\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO candidates (\n",
    "        first_name, last_name, email, application_date, country,\n",
    "        years_of_experience, seniority, technology,\n",
    "        code_challenge_score, technical_interview_score\n",
    "    ) VALUES (\n",
    "        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # Obtener conexión\n",
    "        conn = get_db_connection()\n",
    "        \n",
    "        # Crear cursor\n",
    "        with conn.cursor() as cur:\n",
    "            # Procesar datos en lotes\n",
    "            for i in range(0, len(df), batch_size):\n",
    "                batch = df.iloc[i:i + batch_size]\n",
    "                \n",
    "                # Preparar datos para inserción\n",
    "                values = [tuple(x) for x in batch.values]\n",
    "                \n",
    "                # Ejecutar inserción en lote\n",
    "                cur.executemany(insert_query, values)\n",
    "                \n",
    "                # Commit del lote\n",
    "                conn.commit()\n",
    "                \n",
    "                print(f\"Insertados registros {i} a {i + len(batch)}\")\n",
    "                \n",
    "        print(\"¡Todos los datos han sido insertados exitosamente!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al insertar datos: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Preparar los datos para la inserción\n",
    "def prepare_data_for_insert(df):\n",
    "    \"\"\"\n",
    "    Prepara los datos para la inserción en la base de datos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir la fecha de aplicación al formato correcto\n",
    "        df['Application Date'] = pd.to_datetime(df['Application Date'])\n",
    "        \n",
    "        # Convertir años de experiencia a entero\n",
    "        df['YOE'] = df['YOE'].astype(int)\n",
    "        \n",
    "        # Convertir scores a float\n",
    "        df['Code Challenge Score'] = df['Code Challenge Score'].astype(float)\n",
    "        df['Technical Interview Score'] = df['Technical Interview Score'].astype(float)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error al preparar los datos: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ejecutar la preparación y carga de datos\n",
    "df_prepared = prepare_data_for_insert(df)\n",
    "if df_prepared is not None:\n",
    "    insert_candidates_data(df_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c75adc-0a6a-414d-b237-b3c2155d66e4",
   "metadata": {},
   "source": [
    "**Transformaciones y Análisis final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5753da-fb1a-4878-aeb0-57693b26c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiniciando proceso de transformación...\n",
      "Tabla transformada limpiada exitosamente\n",
      "Procesando 250000 registros...\n",
      "\n",
      "Ejemplo de valores a insertar:\n",
      "['Bernadette', 'Langworth', 'leonard91@yahoo.com', datetime.date(2021, 2, 26), 'Norway', 2, 'Intern', 'Data Engineer', Decimal('3.00'), Decimal('3.00'), False]\n",
      "\n",
      "Ejemplo de valores a insertar:\n",
      "['Bernadette', 'Langworth', 'leonard91@yahoo.com', datetime.date(2021, 2, 26), 'Norway', 2, 'Intern', 'Data Engineer', Decimal('3.00'), Decimal('3.00'), False]\n",
      "\n",
      "Ejemplo de valores a insertar:\n",
      "['Bernadette', 'Langworth', 'leonard91@yahoo.com', datetime.date(2021, 2, 26), 'Norway', 2, 'Intern', 'Data Engineer', Decimal('3.00'), Decimal('3.00'), False]\n",
      "\n",
      "Ejemplo de valores a insertar:\n",
      "['Bernadette', 'Langworth', 'leonard91@yahoo.com', datetime.date(2021, 2, 26), 'Norway', 2, 'Intern', 'Data Engineer', Decimal('3.00'), Decimal('3.00'), False]\n",
      "\n",
      "Ejemplo de valores a insertar:\n",
      "['Bernadette', 'Langworth', 'leonard91@yahoo.com', datetime.date(2021, 2, 26), 'Norway', 2, 'Intern', 'Data Engineer', Decimal('3.00'), Decimal('3.00'), False]\n",
      "\n",
      "Se transformaron y cargaron 250000 registros exitosamente!\n",
      "\n",
      "Resultados de la transformación:\n",
      "Total de registros: 0\n",
      "Candidatos contratados: 0\n",
      "Porcentaje de contratación: 0.00%\n",
      "\n",
      "Contratados por tecnología:\n"
     ]
    }
   ],
   "source": [
    "def transform_and_load_data():\n",
    "    \"\"\"\n",
    "    Aplica transformaciones y carga los datos en la nueva tabla.\n",
    "    \"\"\"\n",
    "    # Query para obtener datos específicos (sin incluir el id ni created_at)\n",
    "    select_query = \"\"\"\n",
    "    SELECT \n",
    "        first_name, last_name, email, application_date, country,\n",
    "        years_of_experience, seniority, technology,\n",
    "        code_challenge_score, technical_interview_score\n",
    "    FROM candidates;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query de inserción corregido\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO candidates_transformed (\n",
    "        first_name, last_name, email, application_date, country,\n",
    "        years_of_experience, seniority, technology,\n",
    "        code_challenge_score, technical_interview_score, hired\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        \n",
    "        # Obtener datos originales\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(select_query)\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                print(\"No se encontraron datos en la tabla original\")\n",
    "                return\n",
    "                \n",
    "            print(f\"Procesando {len(rows)} registros...\")\n",
    "            \n",
    "            # Procesar cada registro\n",
    "            for row in rows:\n",
    "                # Los valores ya vienen en el orden correcto del select\n",
    "                values = list(row)\n",
    "                \n",
    "                # Calcular el valor de hired\n",
    "                code_score = float(values[8]) if values[8] is not None else 0\n",
    "                tech_score = float(values[9]) if values[9] is not None else 0\n",
    "                hired = code_score >= 7 and tech_score >= 7\n",
    "                \n",
    "                # Añadir el valor de hired al final\n",
    "                values.append(hired)\n",
    "                \n",
    "                # Imprimir un ejemplo del primer registro para depuración\n",
    "                if rows.index(row) == 0:\n",
    "                    print(\"\\nEjemplo de valores a insertar:\")\n",
    "                    print(values)\n",
    "                \n",
    "                # Insertar el registro\n",
    "                cur.execute(insert_query, values)\n",
    "            \n",
    "            conn.commit()\n",
    "            print(f\"\\nSe transformaron y cargaron {len(rows)} registros exitosamente!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la transformación y carga: {e}\")\n",
    "        print(\"Valores que causaron el error:\", values if 'values' in locals() else \"No disponible\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Limpiar la tabla transformada antes de insertar\n",
    "def clear_transformed_table():\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"TRUNCATE TABLE candidates_transformed RESTART IDENTITY;\")\n",
    "            conn.commit()\n",
    "            print(\"Tabla transformada limpiada exitosamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al limpiar la tabla: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Ejecutar el proceso completo\n",
    "print(\"Reiniciando proceso de transformación...\")\n",
    "clear_transformed_table()\n",
    "transform_and_load_data()\n",
    "\n",
    "# Verificar los resultados\n",
    "def verify_transformed_data():\n",
    "    \"\"\"\n",
    "    Verifica los datos en la tabla transformada\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        with conn.cursor() as cur:\n",
    "            # Total de registros\n",
    "            cur.execute(\"SELECT COUNT(*) FROM candidates_transformed;\")\n",
    "            total = cur.fetchone()[0]\n",
    "            \n",
    "            # Candidatos contratados\n",
    "            cur.execute(\"SELECT COUNT(*) FROM candidates_transformed WHERE hired = TRUE;\")\n",
    "            hired = cur.fetchone()[0]\n",
    "            \n",
    "            print(f\"\\nResultados de la transformación:\")\n",
    "            print(f\"Total de registros: {total}\")\n",
    "            print(f\"Candidatos contratados: {hired}\")\n",
    "            print(f\"Porcentaje de contratación: {(hired/total)*100 if total > 0 else 0:.2f}%\")\n",
    "            \n",
    "            # Distribución por tecnología\n",
    "            print(\"\\nContratados por tecnología:\")\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT technology, COUNT(*) as total\n",
    "                FROM candidates_transformed\n",
    "                WHERE hired = TRUE\n",
    "                GROUP BY technology\n",
    "                ORDER BY total DESC\n",
    "                LIMIT 5;\n",
    "            \"\"\")\n",
    "            for row in cur.fetchall():\n",
    "                print(f\"{row[0]}: {row[1]} contratados\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error al verificar datos transformados: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "verify_transformed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a4b22-f451-4491-8f77-3ec53ddc3a10",
   "metadata": {},
   "source": [
    "**Análisis Detallado y Visualizaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e657502f-5e32-4f85-9061-a21af6197087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando análisis detallado...\n",
      "\n",
      "Tasa de contratación por país:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre               Total      Contratados  Tasa (%)  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tasa de contratación por tecnología:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre               Total      Contratados  Tasa (%)  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tasa de contratación por años de experiencia:\n",
      "--------------------------------------------------------------------------------\n",
      "Años       Total      Contratados  Tasa (%)  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tasa de contratación por seniority:\n",
      "--------------------------------------------------------------------------------\n",
      "Nivel           Total      Contratados  Tasa (%)  \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def detailed_analysis():\n",
    "    \"\"\"\n",
    "    Realiza un análisis detallado de los datos transformados\n",
    "    \"\"\"\n",
    "    queries = {\n",
    "        \"Tasa de contratación por país\": \"\"\"\n",
    "            SELECT \n",
    "                country,\n",
    "                COUNT(*) as total_candidates,\n",
    "                COUNT(*) FILTER (WHERE hired = TRUE) as hired_candidates,\n",
    "                ROUND(\n",
    "                    (COUNT(*) FILTER (WHERE hired = TRUE) * 100.0 / COUNT(*))::numeric,\n",
    "                    2\n",
    "                ) as hiring_rate\n",
    "            FROM candidates_transformed\n",
    "            GROUP BY country\n",
    "            ORDER BY hiring_rate DESC\n",
    "            LIMIT 10;\n",
    "        \"\"\",\n",
    "        \n",
    "        \"Tasa de contratación por tecnología\": \"\"\"\n",
    "            SELECT \n",
    "                technology,\n",
    "                COUNT(*) as total_candidates,\n",
    "                COUNT(*) FILTER (WHERE hired = TRUE) as hired_candidates,\n",
    "                ROUND(\n",
    "                    (COUNT(*) FILTER (WHERE hired = TRUE) * 100.0 / COUNT(*))::numeric,\n",
    "                    2\n",
    "                ) as hiring_rate\n",
    "            FROM candidates_transformed\n",
    "            GROUP BY technology\n",
    "            ORDER BY hiring_rate DESC\n",
    "            LIMIT 10;\n",
    "        \"\"\",\n",
    "        \n",
    "        \"Tasa de contratación por años de experiencia\": \"\"\"\n",
    "            SELECT \n",
    "                years_of_experience,\n",
    "                COUNT(*) as total_candidates,\n",
    "                COUNT(*) FILTER (WHERE hired = TRUE) as hired_candidates,\n",
    "                ROUND(\n",
    "                    (COUNT(*) FILTER (WHERE hired = TRUE) * 100.0 / COUNT(*))::numeric,\n",
    "                    2\n",
    "                ) as hiring_rate\n",
    "            FROM candidates_transformed\n",
    "            GROUP BY years_of_experience\n",
    "            ORDER BY years_of_experience;\n",
    "        \"\"\",\n",
    "        \n",
    "        \"Tasa de contratación por seniority\": \"\"\"\n",
    "            SELECT \n",
    "                seniority,\n",
    "                COUNT(*) as total_candidates,\n",
    "                COUNT(*) FILTER (WHERE hired = TRUE) as hired_candidates,\n",
    "                ROUND(\n",
    "                    (COUNT(*) FILTER (WHERE hired = TRUE) * 100.0 / COUNT(*))::numeric,\n",
    "                    2\n",
    "                ) as hiring_rate\n",
    "            FROM candidates_transformed\n",
    "            GROUP BY seniority\n",
    "            ORDER BY hiring_rate DESC;\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        with conn.cursor() as cur:\n",
    "            for title, query in queries.items():\n",
    "                print(f\"\\n{title}:\")\n",
    "                print(\"-\" * 80)\n",
    "                cur.execute(query)\n",
    "                results = cur.fetchall()\n",
    "                \n",
    "                if \"país\" in title or \"tecnología\" in title:\n",
    "                    print(f\"{'Nombre':<20} {'Total':<10} {'Contratados':<12} {'Tasa (%)':<10}\")\n",
    "                    print(\"-\" * 80)\n",
    "                    for row in results:\n",
    "                        print(f\"{row[0]:<20} {row[1]:<10} {row[2]:<12} {row[3]:<10}\")\n",
    "                elif \"experiencia\" in title:\n",
    "                    print(f\"{'Años':<10} {'Total':<10} {'Contratados':<12} {'Tasa (%)':<10}\")\n",
    "                    print(\"-\" * 80)\n",
    "                    for row in results:\n",
    "                        print(f\"{row[0]:<10} {row[1]:<10} {row[2]:<12} {row[3]:<10}\")\n",
    "                else:\n",
    "                    print(f\"{'Nivel':<15} {'Total':<10} {'Contratados':<12} {'Tasa (%)':<10}\")\n",
    "                    print(\"-\" * 80)\n",
    "                    for row in results:\n",
    "                        print(f\"{row[0]:<15} {row[1]:<10} {row[2]:<12} {row[3]:<10}\")\n",
    "                        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en el análisis detallado: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Ejecutar el análisis detallado\n",
    "print(\"\\nGenerando análisis detallado...\")\n",
    "detailed_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11308b9f-16dc-4d88-aafa-a79a862d917c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de seaborn\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def read_and_validate_data(csv_path='../data/candidates.csv'):\n",
    "    \"\"\"\n",
    "    Lee y valida los datos del CSV\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Leer el CSV\n",
    "        print(f\"Leyendo archivo: {csv_path}\")\n",
    "        df = pd.read_csv(csv_path, delimiter=';', encoding='utf-8')\n",
    "        print(\"\\nArchivo leído exitosamente!\")\n",
    "        \n",
    "        # Exploración inicial\n",
    "        print(\"\\nDimensiones del DataFrame:\")\n",
    "        print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "        \n",
    "        print(\"\\nColumnas del DataFrame:\")\n",
    "        print(df.columns.tolist())\n",
    "        \n",
    "        print(\"\\nPrimeras 5 filas:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        print(\"\\nInformación del DataFrame:\")\n",
    "        print(df.info())\n",
    "        \n",
    "        print(\"\\nEstadísticas descriptivas:\")\n",
    "        print(df.describe())\n",
    "        \n",
    "        print(\"\\nValores nulos por columna:\")\n",
    "        print(df.isnull().sum())\n",
    "        \n",
    "        # Validación de datos\n",
    "        validations = {\n",
    "            \"Registros totales\": len(df),\n",
    "            \"Columnas esperadas presentes\": all(col in df.columns for col in [\n",
    "                'First Name', 'Last Name', 'Email', 'Application Date', 'Country',\n",
    "                'YOE', 'Seniority', 'Technology', 'Code Challenge Score', 'Technical Interview Score'\n",
    "            ]),\n",
    "            \"Emails únicos\": df['Email'].nunique(),\n",
    "            \"Rango de scores válido\": (\n",
    "                (df['Code Challenge Score'].between(0, 10)) & \n",
    "                (df['Technical Interview Score'].between(0, 10))\n",
    "            ).all()\n",
    "        }\n",
    "        \n",
    "        print(\"\\nResultados de la validación:\")\n",
    "        for check, result in validations.items():\n",
    "            print(f\"{check}: {result}\")\n",
    "            \n",
    "        # Agregar columna de contratados\n",
    "        df['Hired'] = (df['Code Challenge Score'] >= 7) & (df['Technical Interview Score'] >= 7)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_hiring_metrics(df):\n",
    "    \"\"\"Crear gráfico de métricas generales de contratación\"\"\"\n",
    "    total_candidates = len(df)\n",
    "    hired_candidates = df['Hired'].sum()\n",
    "    hire_rate = (hired_candidates / total_candidates) * 100\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    metrics = ['Total Candidatos', 'Candidatos Contratados', 'Tasa de Contratación (%)']\n",
    "    values = [total_candidates, hired_candidates, hire_rate]\n",
    "    \n",
    "    ax = sns.barplot(x=metrics, y=values)\n",
    "    \n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(i, v, f'{v:,.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Métricas de Contratación')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_technology_distribution(df):\n",
    "    \"\"\"Crear gráfico de distribución por tecnología\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    tech_counts = df['Technology'].value_counts()\n",
    "    \n",
    "    plt.pie(tech_counts.values, labels=tech_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Distribución por Tecnología')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_experience_vs_hiring(df):\n",
    "    \"\"\"Crear gráfico de experiencia vs contratación\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    exp_hire = df.groupby('YOE').agg({\n",
    "        'Hired': ['count', 'sum']\n",
    "    }).reset_index()\n",
    "    exp_hire.columns = ['YOE', 'Total', 'Hired']\n",
    "    \n",
    "    sns.barplot(x='YOE', y='Total', data=exp_hire, color='lightblue', label='No Contratados')\n",
    "    sns.barplot(x='YOE', y='Hired', data=exp_hire, color='darkblue', label='Contratados')\n",
    "    \n",
    "    plt.title('Contrataciones por Años de Experiencia')\n",
    "    plt.xlabel('Años de Experiencia')\n",
    "    plt.ylabel('Número de Candidatos')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_country_distribution(df):\n",
    "    \"\"\"Crear gráfico de distribución por país\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    top_countries = df['Country'].value_counts().head(10)\n",
    "    \n",
    "    ax = sns.barplot(y=top_countries.index, x=top_countries.values, palette='viridis')\n",
    "    \n",
    "    for i, v in enumerate(top_countries.values):\n",
    "        ax.text(v, i, f' {v:,}', va='center')\n",
    "    \n",
    "    plt.title('Top 10 Países de Origen')\n",
    "    plt.xlabel('Número de Candidatos')\n",
    "    plt.ylabel('País')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_score_distribution(df):\n",
    "    \"\"\"Crear gráfico de distribución de puntajes\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    sns.histplot(data=df, x='Code Challenge Score', bins=20, ax=ax1)\n",
    "    ax1.axvline(x=7, color='r', linestyle='--', label='Umbral de aprobación')\n",
    "    ax1.set_title('Distribución de Code Challenge Scores')\n",
    "    ax1.legend()\n",
    "    \n",
    "    sns.histplot(data=df, x='Technical Interview Score', bins=20, ax=ax2)\n",
    "    ax2.axvline(x=7, color='r', linestyle='--', label='Umbral de aprobación')\n",
    "    ax2.set_title('Distribución de Technical Interview Scores')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_summary_statistics(df):\n",
    "    \"\"\"Imprimir estadísticas resumen\"\"\"\n",
    "    print(\"\\nEstadísticas Resumen:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total de candidatos: {len(df):,}\")\n",
    "    print(f\"Candidatos contratados: {df['Hired'].sum():,}\")\n",
    "    print(f\"Tasa de contratación: {(df['Hired'].mean() * 100):.1f}%\")\n",
    "    print(f\"\\nPromedio de años de experiencia: {df['YOE'].mean():.1f} años\")\n",
    "    print(f\"Mediana de años de experiencia: {df['YOE'].median():.1f} años\")\n",
    "    print(\"\\nDistribución por Seniority:\")\n",
    "    print(df['Seniority'].value_counts().to_string())\n",
    "    print(\"\\nPuntajes promedio:\")\n",
    "    print(f\"Code Challenge: {df['Code Challenge Score'].mean():.2f}\")\n",
    "    print(f\"Technical Interview: {df['Technical Interview Score'].mean():.2f}\")\n",
    "\n",
    "def display_all_visualizations(df):\n",
    "    \"\"\"Mostrar todos los gráficos\"\"\"\n",
    "    print_summary_statistics(df)\n",
    "    plot_hiring_metrics(df)\n",
    "    plot_technology_distribution(df)\n",
    "    plot_experience_vs_hiring(df)\n",
    "    plot_country_distribution(df)\n",
    "    plot_score_distribution(df)\n",
    "\n",
    "# Uso del código:\n",
    "# 1. Primero leer y validar los datos\n",
    "df = read_and_validate_data()\n",
    "\n",
    "# 2. Si la lectura fue exitosa, mostrar las visualizaciones\n",
    "if df is not None:\n",
    "    display_all_visualizations(df)\n",
    "else:\n",
    "    print(\"No se pudieron cargar los datos. Por favor verifica la ruta del archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de245361-f53d-41dd-adf2-379c848c0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\juant\\onedrive\\documentos\\uao\\maestría\\primer semestre\\etl\\actividad 1\\extract-workshop-001\\venv\\lib\\site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\juant\\onedrive\\documentos\\uao\\maestría\\primer semestre\\etl\\actividad 1\\extract-workshop-001\\venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\juant\\onedrive\\documentos\\uao\\maestría\\primer semestre\\etl\\actividad 1\\extract-workshop-001\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juant\\onedrive\\documentos\\uao\\maestría\\primer semestre\\etl\\actividad 1\\extract-workshop-001\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.7/8.0 MB 18.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.0 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.4/2.6 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834be09c-b078-44e1-b29c-c8485ac5ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
